---
layout: post
title: (Multi)PLIER Explained
description: "The key ideas behind PLIER, and why unsupervised learning makes sense in transcriptomics"
cover-img: "/assets/img/traintracks.jpg"
tags: ['machine learning', 'transfer learning', 'unsupervised learning']
---

## Intro/Motivation
- There is a lot of gene expression data out there
- There will never be a lot of data for individual rare diseases 
- Maybe it's possible to use information from the big dataset to learn about the small dataset

## PLIER
The idea behind [PLIER](https://www.nature.com/articles/s41592-019-0456-1) is to "infer a biologically grounded data generating model that provides estimates of underlying biological processes, including explicitly identified pathway-level and cell-type proportion effects" using matrix decomposition.
If that description made sense to you, you can probably skip ahead to the [MultiPLIER](#multiplier) section.
If you're like me, and there are a lot of things going on in that sentence that didn't quite parse, read on.

In nontechnical terms, PLIER finds a small number of explanations (called latent variables) for a large number of changes in gene expression.
In doing so, it makes three main assumptions:
1) There are, in fact, a small number of factors that explain changes in gene expression (a.k.a. the manifold hypothesis)
2) Good explanations are likely to be related to known biological pathways and genesets
3) The relationships between the explanations and the gene expression in linear

<a id="manifold"></a>
### The Manifold Hypothesis
The [manifold hypothesis](https://deepai.org/machine-learning-glossary-and-terms/manifold-hypothesis) is the assumption that a high-dimensional space can be modeled by a low-dimensional one.
Since the term "dimensionality" will come up frequently, it's worth being more explicit about what it means.
In this usage, "dimension" refers to how many numbers it takes to describe a datapoint.
For example, gene expression is described as [high-dimensional](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6989881/) because a single sample has tens of thousands of genes.

Is it really necessary to know the expression of every gene though? 
Probably not.
If you were working with bacteria, you could have a latent variable called "[lac repressor level](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2776167/#Sec2title)" that would describe how much expression you'd expect from multiple *lac* genes.

### Pathways
Being able to describe gene expression in a small number of variables useful on its own.
If you have four samples, you could just memorize the expression and describe it with one variable ('which sample is the gene expression from').
In practice, things like batch effects make good predictors of gene expression that are useless outside the original dataset.

We want a model of gene expression that describes future data, so spurious predictors won't do.
The novel contribution of PLIER is to steer the model away from spurious predictors by grounding the model with biological prior knowledge.
I'll [go into more detail](#pathway) in the next section to explain how they accomplish that.

### Linear Relationships
This is a common assumption that is both probably untrue and probably useful.
Gene expression regulation isn't really a linear process i.e. 2 more molecules of inhibitor != 2 fewer rounds of transcription.
That being said, because there are so many genes that need to be described, using a more complicated model may not be helpful[^thesis].

## How does PLIER work?
There are a lot of details and a lot of math that go into making PLIER work.
The short summary is that PLIER creates a model that transforms gene expression data into latent variable measurements by:

1. Maximimizing how well the latent variables are able to recreate the original data, while
2. Encouraging the latent variables to look like gene sets,
3. Encouraging the weight of each latent variable to be small, and
4. Encouraging each latent variable to correspond to one or few gene sets.

If that makes intuitive sense, feel free to move on to the applications section.
Otherwise, here is a more in-depth description

## How does PLIER _really_ work
PLIER is based on matrix factorization, so understanding PCA/matrix factorization more generally will help understand this section.
I explain the process in terms of finding explanations for data, but other interpretations like rotating the data or minimizing variance may make more sense to you.

The best starting place for understanding PLIER specifically is probably the figure below.

TODO insert PLIER_overview figure

This figure shows what the model learns (green) and what is used as input (grey).

The rectangles are helpful if you are familiar with linear algebra, but in English the pieces of the puzzle are:

Inputs:  
*C* - A matrix that describes which genes are in which gene sets  
*Y* - The samples of gene expression used to teach the model how gene expression looks

Outputs:  
*Z* - A matrix turns samples of gene expression into latent variables  
*B* - The amount of each latent variable present in each sample  
*U* - Which pathways should be present in each latent variable

PLIER then decides what values each of the outputs should have by optimizing the following equation:

TODO insert PLIER equation

In this section I'll go through each term in the equation to explain what is happening.

### Reconstruction
TODO insert reconstruction highlighted image

The first term in the equation minimizes reconstruction loss.
That is to say, it minimizes the difference[^MSE] between the original data and the reconstructed version you get when you convert the data to latent variables and back you get when you convert the data to latent variables and back.

If you've read about PCA or SVD, this term will be very familiar.
If not, the intuition is that because you're using a small number of variables to describe the original expression, you often won't be able to describe it perfectly.
The information that is lost is referred to as the reconstruction error, and we want to minimize it to ensure the variables are good at explaining gene expression.

### Pathway Penalty
TODO pathway penalty image

This is PLIER's secret sauce[^title].
Instead of solely minimizing the reconstruction error like in other matrix factorization methods, PLIER pushes the latent variables to look like the gene sets given as prior knowledge.

### Latent Variable Regularization
TODO L2 term

This is a bit of a technical detail, but the latent variables are encouraged to stay small via an [L2 norm](https://mathworld.wolfram.com/L2-Norm.html).
There isn't much of a biological interpretation behind this, it just makes sure that no individual latent variable tries to explain too much of the data.

### Geneset Regularization
TODO geneset term

The final term ensures that the pathway matrix is sparse.
That is to say that each latent variables should only represent one or a few pathways.

<a id="multiplier"></a>
## Applying PLIER
Great, now we have a method called PLIER that transforms gene expression into latent variables.
How do we use it?

The use of PLIER that I think is most interesting is to use it to learn signals from big datasets and apply them to smaller datasets.
One great example of this is the [MultiPLIER paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6538307/)[^disclosure].

The MultiPLIER paper found three main results:
1. You can train a PLIER model on one dataset and learn latent variables that are relevant in another dataset, and
2. You can train a PLIER model on a huge compendium of expression data and do as well or better than a model trained on a tissue-specific dataset, so
3. You can use the latent variables from a PLIER model trained on a large compendium to find signals relevant across tissue types in the same disease.

These results open up a lot of potential research directions.
For example, MultiPLIER shows that it's possible to use PLIER for unsupervised transfer learning[^tl].
As a result, we can avoid some of the information loss when using PLIER for small data problems by training it on a big dataset.

Additionally, MultiPLIER shows that PLIER can be useful to learn more about diseases where samples are drawn from multiple tissues.
It can be hard to integrate data from across tissue types due to differences in relevant biological pathways, but PLIER does that for free if it's trained on a big enough initial dataset.

More concretely, you can run differential expression in latent variable space rather than gene space since you'll have more power with fewer variables.
You can then work backwards to determine which biological features the latent variables describe.

### Footnotes 
[^thesis]: Actually my thesis is something to the effect of "now that we have millions of samples maybe we can do better than linear models", so I hope this isn't true :)
[^title]: Or maybe not so secret, it's the entirety of the method's name once you expand the acronym
[^MSE]: Technically the mean squared error
[^disclosure]: Full disclosure, this paper is from the lab I'm doing my PhD in. This is unsurprising though. I frequently have good ideas, Google them, and learn that not only have they already been done, they were done by a Greenelab member.
[^tl]: Unsupervised meanining "you only need the expression data to learn something" and transfer learning meaning "you can start get information from a dataset other than the one you're studying"
