---
layout: post
title: Reproducible Programming for Biologists Who Code
subtitle: "Part 2: Should Dos"
description: "How to convert code into good code"
cover-img: "/assets/img/cherry_blossoms.jpg"
citable: true
---

<a id="overview"></a>
# Overview
This post covers all of the things one should do to help make their code reproducible.
Nothing in this post is absolutely critical like the topics in the previous post, but they will all increase the probability that others can reproduce your findings.
Feel free to pick and choose which things to implement from this post; each of them will make your code better.
However, as the title says, you should do all of them if you can.


Today's post is the second in a trilogy of posts about reproducible science.
The previous post can be found [here](https://ben-heil.github.io/2020-06-16-mustdo/).

#### Table of Contents:
- [Overview](#overview)
- [Runnable Code](#running)
- - [Have a Science Button](#button)
- - [Avoid Hardcoded Paths](#paths)
- - [README Redux](#readme)
- - [Test Elsewhere](#rerun)
- [Readable Code](#reading)
- - [Commenting](#commenting)
- - [Repo Organization](#setup)
- - [Code Organization](#code)
- - [Avoiding Magic Numbers](#magic)

<a id="running"></a>
## Runnable Code

One key to reproducibility is making sure that you're not the only person who can run your code.
This section contains a number of tips that make it more likely that other people can reproduce your analysis.

<a id="button"></a>
### Have a Science Button
<figure class="image">
  <img src=" https://static.miraheze.org/allthetropeswiki/5/53/Big-red-button_kim-possible_6483.jpg " alt="Self Destruct Button">
    <figcaption> Photo Creds: Kim Possible</figcaption>
</figure>

Every mad scientist knows that the culmination of their work should have a large button labeled "[Self Destruct](https://tvtropes.org/pmwiki/pmwiki.php/Main/SelfDestructMechanism)".
As (mostly) sane scientists, we should aspire to have a button labeled "Do Science" instead.
The ideal to work toward is a single script that you can run to do your entire project.

"But wait Ben, I'm reading the sections in reverse order!
Doesn't the [code organization](#code) section say to split code into smaller files?"

That's correct.
The trick is to have all of your setup and analysis scripts strung together.

The simplest way to combine everything is to make a single bash script that runs all of your individual scripts one by one.
While a bash script is a perfectly valid way of doing things, programs called workflow management systems are designed to make putting everything together easier.

Workflow management systems remove inefficiencies that you might run into with a bash script.
For example, if some of the samples in your analysis fail to run correctly workflow management systems make it simple to rerun the analysis on just the failed samples.
Common patterns like reading in files with similar names and producing files with the same names but different extensions are also made easier.

[Snakemake](https://snakemake.readthedocs.io/en/stable/) and [Nextflow](https://www.nextflow.io/index.html) are two examples of workflow management systems designed with an eye towards biology.
[Galaxy](https://usegalaxy.org/) has more limited functionality, but is useful if you would rather work in a graphical environment than with scripts.

#### Further Reading:
- [Snakemake tutorial](https://snakemake.readthedocs.io/en/stable/tutorial/basics.html) based around variant calling
- Nextflow BLAST [pipeline example](https://www.nextflow.io/example3.html)
- Galaxy [sequence assembly example](https://training.galaxyproject.org/training-material/topics/assembly/)


<a id="paths"></a>
### Avoid Hardcoded Paths
If my old code is any reliable estimate, manually setting (hardcoding) paths is the most common way to make code unrunnable.
While `in_file = open('/home/ben/Desktop/data.txt')` worked when I first wrote it, I no longer have the patience to open my code and modify all the paths each time I use it somewhere new.

There are three main ways to avoid hardcoding paths, each of which has pros and cons.
The first method is to file paths as command line arguments using packages like [argparse](https://docs.python.org/3/library/argparse.html) for python
and [argparser](https://cran.r-project.org/web/packages/argparser/argparser.pdf) for R.
This method works best when you only have one or a few input files to keep track of, because while `python calculate_gc.py sample_1.fasta` is fine,
`python run_analysis.py --vcf sample_1.vcf --reference hg38 --annotation annotation.ref --out_file out.txt` is painful to have to type repeatedly.

In programming laziness is a virtue, so ideally we want to avoid typing parameters repeatedly.
The best way to handle lots of parameters is to use a configuration file.
The idea behind a configuration file is that all your paths and settings for all your scripts live in one place so you only have to change one file to modify an analysis.
There are [a number](https://docs.python.org/3.5/library/configparser.html#module-ConfigParser) [of ways](https://hydra.cc/docs/intro/) [to handle](https://cran.r-project.org/web/packages/config/vignettes/introduction.html)
[config files](https://cran.r-project.org/web/packages/configr/vignettes/configr.html) in both python and R.
There is a broad range of potential functionalities, so just pick one that is comfortable for you.
While this method saves a lot of parameter typing, it is less well suited for situations where you want to run the same analysis several times while varying the parameters.

The final way to avoid hardcoded paths is to set all paths relative to the root of the repository.
This method works particularly well in cases where you are using publicly available data and [your download script](https://ben-heil.github.io/2020-06-16-mustdo/#data-access) specifies the location the data will be stored.
Using relative paths is great until it isn't.
If you ever want to switch out the data you're using you're back to the original problem of going through each file and changing paths.
As a result, I tend to prefer using the first two methods before this one.

I've added some example code for each method below to help you decide which method is best for you.
``` python
# Command line arguments
import argparse
parser = argparse.argument_parser(description='This script reads in a file as an example')
parser.add_argument('in_file_path', help='The path to the file to read int')
args = parser.parse_args()

with open(args.in_file_path) as in_file:
    pass
```

``` python
# Config file
import configparser
config = configparser.ConfigParser()

# This is the sort of hardcoded path to avoid, I've used it here for brevity
config.read('settings.cfg')

with open(config.in_file_path) as in_file:
    pass
```

``` python
# Relative Paths
import os

current_directory = os.path.dirname(os.path.abspath(__file__))
in_file_path = os.path.join(current_directory, '../data/in_file.csv')

with open(in_file_path) as in_file:
    pass
```


<a id="readme"></a>
### README Redux
In the previous post I talked about [the components required for a minimal README file](https://ben-heil.github.io/2020-06-16-mustdo/#read-me).
There are other elements that can be added to make life easier though.
The main one is a description of how your directory is set up.
A [description of what each script does](https://github.com/greenelab/BioBombe#analysis-modules) can be helpful for users who already have intermediate files, or who want to modify part of the code.
Likewise, a description of where everything lives in your repository may be helpful, especially if you use a nonstandard method for [directory organization](#setup).


<a id="rerun"></a>
### Test Elsewhere
So you've gotten everything working!
You pushed your science button, everything ran, and the figures that came out at the end are exactly what you expected.
Now it's time to find out whether your code actually works.
The best way to do this is to go to another computer, [download your code](https://ben-heil.github.io/2020-06-16-mustdo/#publishing), and run the whole thing again.
If you're like most people and don't have multiple computers to work with, you can do the same thing by moving to a different directory,
[removing your Conda environment](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#removing-an-environment),
and then downloading/rerunning everything.

Rerunning your code helps you find the [hardcoded paths](#paths) you didn't know were still there,
the [manual steps](https://ben-heil.github.io/2020-06-16-mustdo/#manual) you forgot were necessary,
and the [libraries](https://ben-heil.github.io/2020-06-16-mustdo/#packages) that turned out to not be in the environment file.



<a id="reading"></a>
## Readable Code

I used to believe that making my code readable wasn't important if I was working on projects that I expected to be the only one to use.
After going back to old projects with uncommented functions enough times I realized that I was shooting myself in the foot.
I would often have to resolve the original problem in order to figure out what the different parts of the code were doing.

This section covers a number of ways to keep this from happening to you.
When thinking about the audience for your code, it's often easiest to write for a version of yourself a year in the future.
If future you wouldn't be able to follow what's going on, other users will certainly struggle.


<a id="commenting"></a>
### Documentation

Documentation is a broad subject, with [entire](https://realpython.com/documenting-python-code/#commenting-vs-documenting-code) [posts](https://devguide.python.org/documenting/)
dedicated to it and entire [software packages](https://www.sphinx-doc.org/en/master/) designed to make the result more convenient.
As this guide is dedicated to getting the most value with the least effort, I won't go too far into the weeds.
Instead I will cover what I see as the two most important parts: naming and commenting.

#### Naming

Ideas about the correct way to name functions and variables fall along a sliding scale of brevity.
[On one end](https://www.goodreads.com/book/show/3735293-clean-code) you have the idea that each name should be so perfectly descriptive that
comments should feel unnecessary.
On the other exteme you have the mathematical ideal: every variable is a single letter, with meaning implied by the language the character is pulled from and past code that used the same letter.
In this system the variables are explained in comments, but their names are left brief to avoid masking the beauty of the algorithm or something.

As an avid reader of [Pat Rothfuss's books](https://www.goodreads.com/author/quotes/108424.Patrick_Rothfuss), I lean towards the more verbose side of the spectrum.
Descriptive variable names [are](https://hackernoon.com/the-art-of-naming-variables-52f44de00aad) [generally](https://towardsdatascience.com/data-scientists-your-variable-names-are-awful-heres-how-to-fix-them-89053d2855be)
[considered](https://blog.usejournal.com/naming-your-variables-f9477ba002e9) to be the better way of operating.
Single letter variable names are reserved for loop control (e.g. `for i in range(10)`) and for actual mathematical equations.

#### Commenting

Commenting code is fairly straightforward, and something that most people know they should do.
What you might not know is that there are standards designed for easing some of the cognitive burden on how to structure your comments.
These methods typically also integrate with software to convert [comments into documentation websites](https://www.sphinx-doc.org/en/master/).

In R, [roxygen2](https://github.com/r-lib/roxygen2#usage) implements a standard way of writing comments.
It is the only one I am aware of, thoughit is also possible there are others.

In python, the two main commenting standards are [reStructuredText](https://queirozf.com/entries/python-docstrings-reference-examples#restructuredtext-rest)
and [Google](http://google.github.io/styleguide/pyguide.html)/[NumPy](https://numpydoc.readthedocs.io/en/latest/format.html#documenting-modules) style.
Examples of both are shown below to help select a favorite.

``` python
# NumPy Style
def get_gene_count(gene_file):
	'''Count the number of genes in a file produced
	by `microarray_rnaseq_gene_intersection.py`

	Arguments
	---------
	gene_file: str or Path
		The path to a file containing the list of genes created by
		microarray_rnaseq_gene_intersection.py

	Returns
	-------
	num_genes: int
		The number of genes present in the gene file
	'''
```
``` python
# reStructuredText
def get_gene_count(gene_file):
	'''Count the number of genes in a file

	Count the number of genes in a file. The expected file format
	is that of a file produced by
	microarray_rnaseq_gene_intersection.py

	:param str gene_file: The path to a file containing genes
	:return: The number of genes present in the gene file
	'''
```

Regardless of how you choose to style your comments, what is important is that you have a description for each file and function.
Inline comments about individual code parts can be used at your discretion.


<a id="setup"></a>
### Repository Organization

With some minor variation, academic publications all have the same sections.
Every paper you read will have sections titled introduction, methods, results, and so on.
It's not necessary for papers to be organized this way, but it reduces the cognitive burden of reading a new paper and makes it easier to find things.

Code repositories should be organized for the same reason.
Like academic papers most repositories have a similar base layout, shown below, but there are some variations.
In this diagram all the bolded words are names of directories, while the unbolded words are individual files.

- **\<Project Name\>**
- - **data**
- - **code**
- - **output**
- - README.txt
- - LICENSE

The data directory is pretty self explanatory.
It stores the data files that your analyses are run on.
You can also create subdirectories for [raw and processed](https://medium.com/outlier-bio-blog/a-quick-guide-to-organizing-data-science-projects-updated-for-2016-4cbb1e6dac71)
data files to keep track of both the original data and the data the analyses are run on.

The code directory has a lot more variation.
For starters, in python projects the code directory will typically have the same name as the project itself.
This is because, [with a little extra work](https://python-packaging-tutorial.readthedocs.io/en/latest/setup_py.html), the code can be installed as a module and used in other projects.
Code directories are also frequently split into two directories: one code directory and one directory for notebooks.
This allows a logical separation between analysis code which goes in notebooks and supporting code which goes in the code directory.

The output directory stores the results of your analyses.
Typically for academic projects, the output directory will contain visualizations that become figures in a paper.

Back in the main directory there is a README file, which we've [already discussed](#readme), and a license file.
The license file is important, because otherwise others are unable to use your code.
For help on deciding on a license [peruse this website](https://choosealicense.com/licenses/).

<a id="code"></a>
### Code Organization

When I started writing code, my projects tended to be a single file with hundreds of lines of code and zero functions.
In order to work on the project I needed to have hours of uninterrupted time to hold the entire project in my head and determine the next steps.
In addition to being a headache to work with, I ended up making errors because I didn't fully understand what was going on.
Over time, I found that the solution to this monolithic design pattern was to split code into different files and functions.

#### Functions

Programs are most understandable when they are split into subportions that are progressively less abstract.
To demonstrate, let's make a cake.

``` python
# With functions
def preheat_oven():
    oven.set_temp(325)

def mix_batter():
    mix_butter()
    mix_liquids()
    combine_butter_and_liquids()

def bake_cake():
    oven.insert_cake()
    time.sleep(1800)
    oven.remove_cake()

def make_cake():
    preheat_oven()
    mix_batter()
    bake_cake()
```

``` python
# Without functions
oven.set_temp(325)
bowl.add(butter)
mixer.mix(bowl1)
bowl.add(sugar)
bowl.add(baking_powder)
bowl.add(salt)
bowl.add(eggs)
oven.insert_cake()
time.sleep(1800)
oven.remove_cake()
```

It's much more simple to understand the code with functions than the code without.
As the scale of a project grows it becomes increasingly difficult for the latter type of code to work.
For example, if you wanted to bake the cake for less long it is far more obvious where a change should be made in the former code than the latter.

The easiest way to end up writing code in functions instead of slabs is to plan what you're writing ahead of time.
Instead of trying to write an entire analysis fully formed, write out each portion as a comment, then convert that comment into a function.
For me, at least, it is much simpler to think about what is involved in mixing a batter than keeping every step of the recipe in my head.

#### Files
Usually around the second analysis of a project, I end up needing code stored in the first analysis file.
I begin to copy-paste the code, only to hear the words of my undergrad CS teacher in my head:
> When you press the copy button, say to yourself 'I am.'
> Then, when you press the paste button, say to yourself 'making a mistake.'

Properly scolded, I take the code and move it to a function called in both analyses.

Eventually I end up with enough functions called in multiple analyses that it's worth putting them in their own file.
By convention, that file is usually called `utils` or `utilities`.
Once it is too large, the utilities file can be further split into more specialized files like a `data_utils` file.

On the analysis side, the biggest help in repo organization is to [prepend a number](https://github.com/greenelab/BioBombe/tree/master/0.expression-download)
to the script names so users know which order to run them in.
Additionally, each analysis should be in its own file with a descriptive name.


<a id="magic"></a>
### Avoiding Magic Numbers

As cool as they sound, [magic numbers](https://wiki.c2.com/?MagicNumber) are not good programming practice.
For example, if you're accessing a part of a csv file, you probably should read in the header and determine the location of the correct column instead of writing `gene = row.split(',')[2]`.
If the magical number is something that will always be the same, state that in your code.
Instead of `area = 3.14 * radius **2`, use
``` python
PI = 3.14
area = PI * radius ** 2
```

Finally, if using a number in your code is unavoidable, be sure to leave a comment to explain what it means.


## Acknowledgements
Thank you to [Rachel Ungar](https://twitter.com/raungar) for her expertise in snakemake.

