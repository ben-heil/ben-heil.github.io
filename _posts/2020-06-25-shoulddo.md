---
layout: post
title: Reproducible Programming for Biologists Who Code
subtitle: "Part 2: Should Dos"
description: "How to convert code into good code"
cover-img: "/assets/img/cherry_blossoms.jpg"
citable: true
---

<a id="overview"></a>
# Overview

#### Table of Contents:
- [Overview](#overview)
- [Runnable Code](#running)
- - [Have a Science Button](#button)
- - [Avoid Hardcoded Paths](#paths)
- - [README Redux](#repos)
- - [Test Elsewhere](#rerun)
- [Readable Code](#reading)
- - [Commenting](#commenting)
- - [Linting](#linting)
- - [Repo Organization](#setup)
- - [Don't Repeat Yourself](#dry)
- [Robust Code](#robust)
- - [Using Version Control](#github)
- - [Avoiding Magic Numbers](#magic)

<a id="running"></a>
## Runnable Code

<a id="button"></a>
### Have a Science Button
<figure class="image">
  <img src=" https://static.miraheze.org/allthetropeswiki/5/53/Big-red-button_kim-possible_6483.jpg " alt="Self Destruct Button">
    <figcaption> Photo Creds: Kim Possible</figcaption>
</figure>

Every mad scientist knows that the machine that is culmination of their work should have a large button on it labeled "[Self Destruct](https://tvtropes.org/pmwiki/pmwiki.php/Main/SelfDestructMechanism)".
As sane scientists, we should aspire to have a button labeled "Do Science".
The ideal to work toward is to have a single script that you can run to do your entire project.

"But wait Ben, I'm reading the sections in reverse order!
Doesn't the [repository organization](#setup) section say to split code into smaller files?"

That's correct.
The trick is to have all of your setup and analysis scripts strung together by some method.

The simplest way to combine everything is to make a single bash script that runs all of your individual scripts one by one.
While a bash script is a perfectly valid way of doing things, programs called workflow management systems are designed to make putting everything together easier.

Workflow management systems remove inefficiencies that you might run into with a bash script.
For example, if some of the samples in your analysis fail to run correctly workflow management systems make it simple to rerun the analysis on just the failed samples.
Common patterns like reading in files with similar names and producing files with the same names but different extensions are also made easier.

[Snakemake](https://snakemake.readthedocs.io/en/stable/) and [Nextflow](https://www.nextflow.io/index.html) are two examples of workflow management systems designed with an eye towards biology.
[Galaxy](https://usegalaxy.org/) has more limited functionality, but is useful if you would rather work in a graphical environment than with scripts.

### Further Reading:
- [Snakemake tutorial](https://snakemake.readthedocs.io/en/stable/tutorial/basics.html) based around variant calling
- Nextflow BLAST [pipeline example](https://www.nextflow.io/example3.html)
- Galaxy [sequence assembly example](https://training.galaxyproject.org/training-material/topics/assembly/)


<a id="paths"></a>
### Avoid Hardcoded Paths
If my old code is any reliable estimate, manually setting (hardcoding) paths is the most common way to make code unrunnable.
While `in_file = open('/home/ben/Desktop/data.txt')` worked when I first wrote it, I no longer have the patience to open my code and modify all the paths each time I use it somewhere new.

There are three main ways to avoid hardcoding paths, each of which has pros and cons.
The first method is to file paths as command line arguments using packages like [argparse](https://docs.python.org/3/library/argparse.html) for python
and [argparser](https://cran.r-project.org/web/packages/argparser/argparser.pdf) for R.
This method works best when you only have one or a few input files to keep track of, because while `python calculate_gc.py sample_1.fasta` is fine,
`python run_analysis.py --vcf sample_1.vcf --reference hg38 --annotation annotation.ref --out_file out.txt` is painful to have to type repeatedly.

In programming laziness is a virtue, so ideally we want to avoid typing parameters repeatedly.
The best way to handle lots of parameters is to use a configuration file.
The idea behind a configuration file is that all your paths and settings for all your scripts live in one place so you only have to change one file to modify an analysis.
There are [a number](https://docs.python.org/3.5/library/configparser.html#module-ConfigParser) [of ways](https://hydra.cc/docs/intro/) [to handle](https://cran.r-project.org/web/packages/config/vignettes/introduction.html)
[config files](https://cran.r-project.org/web/packages/configr/vignettes/configr.html) in both python and R.
There is a broad range of potential functionalities, so just pick one that is comfortable for you.
While this method saves a lot of parameter typing, it is less well suited for situations where you want to run the same analysis several times while varying the parameters.

The final way to avoid hardcoded paths is to set all paths relative to the root of the repository.
This method works particularly well in cases where you are using publicly available data and [your download script](https://ben-heil.github.io/2020-06-16-mustdo/#data-access) specifies the location the data will be stored.
Using relative paths is great until it isn't.
If you ever want to switch out the data you're using you're back to the original problem of going through each file and changing paths.
As a result, I tend to prefer using the first two methods before this one.

I've added some example code for each method below to help you decide which method is best for you.
``` python
# Command line arguments
import argparse
parser = argparse.argument_parser(description='This script reads in a file as an example')
parser.add_argument('in_file_path', help='The path to the file to read int')
args = parser.parse_args()

with open(args.in_file_path) as in_file:
    pass
```

``` python
# Config file
import configparser
config = configparser.ConfigParser()

# This is the sort of hardcoded path to avoid, I've used it here for brevity
config.read('settings.cfg')

with open(config.in_file_path) as in_file:
    pass
```

``` python
# Relative Paths
import os

current_directory = os.path.dirname(os.path.abspath(__file__))
in_file_path = os.path.join(current_directory, '../data/in_file.csv')

with open(in_file_path) as in_file:
    pass
```


<a id="repos"></a>
### README Redux
In the previous post I talked about [the components required for a minimal README file](https://ben-heil.github.io/2020-06-16-mustdo/#read-me).
There are other elements that can be added to make life easier though.
The main one is a description of how your directory is set up.
A [description of what each script does](https://github.com/greenelab/BioBombe#analysis-modules) can be helpful for users who already have intermediate files, or who want to modify part of the code.
Likewise, a description of where everything lives in your repository may be helpful, especially if you use a nonstandar method for [directory organization](#setup)


<a id="rerun"></a>
### Test Elsewhere
So you've gotten everything working!
You pushed your science button, everything ran, and the figures that came out at the end are exactly what you expected.
Now it's time to find out whether your code actually works.
The best way to do this is to go to another computer, [download your code](https://ben-heil.github.io/2020-06-16-mustdo/#publishing), and run the whole thing again.
If you're like most people and don't have multiple computers to work with, you can do the same thing by moving to a different directory,
[removing your Conda environment](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#removing-an-environment),
and then downloading/rerunning everything.

Rerunning your code helps you find the [hardcoded paths](#paths) you didn't know were still there,
the [manual steps](https://ben-heil.github.io/2020-06-16-mustdo/#manual) you forgot were necessary,
and the [libraries](https://ben-heil.github.io/2020-06-16-mustdo/#packages) that turned out to not be in the environment file.



<a id="reading"></a>
## Readable Code

<a id="commenting"></a>
### Commenting

- Comment your code; each file and function should have a comment stating what it does. For recommendations on format, see numpy style

<a id="linting"></a>
### Linting

<a id="setup"></a>
### Repository Organization

Separate the running and analysis logic. Preferably via bash scripts

<a id="dry"></a>
### Don't Repeat Yourself

<a id="robust"></a>
## Robust Code

<a id="github"></a>
### Using Version Control

<a id="magic"></a>
### Avoiding Magic Numbers
